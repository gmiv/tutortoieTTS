## TutortoieTTS

High-quality TTS built on Tortoise-TTS v3.0.0 with simple CLI and voice cloning.

---

## üìä Complete Preset Parameters Reference

### Quick Reference: Preset-Specific Parameters

These are the **only** parameters that differ between presets. All other parameters use the same defaults (shown below).

| Preset | `num_autoregressive_samples` | `diffusion_iterations` | `cond_free` |
|--------|----------------------------:|----------------------:|:-----------:|
| **ultra_fast** | 16 | 30 | `False` |
| **fast** | 96 | 80 | `True` |
| **standard** | 256 | 200 | `True` |
| **high_quality** | 256 | 400 | `True` |

### Default Parameters (Applied to All Presets)

These values are used by **all presets** unless explicitly overridden:

| Parameter | Default Value | Description |
|-----------|--------------:|-------------|
| `temperature` | `0.8` | Controls randomness in autoregressive sampling |
| `length_penalty` | `1.0` | Penalizes longer sequences (higher = shorter output) |
| `repetition_penalty` | `2.0` | Penalizes repetition (higher = less repetition) |
| `top_p` | `0.8` | Nucleus sampling threshold (lower = more focused) |
| `cond_free_k` | `2.0` | Classifier-free guidance strength |
| `diffusion_temperature` | `1.0` | Controls variance in diffusion noise |

---

## üî¨ Deep Dive: Parameter Explanations

### Preset-Specific Parameters

#### `num_autoregressive_samples` (1-512)
**What it does**: Number of candidate sequences generated by the GPT-2 autoregressive model. The model generates multiple samples and selects the best one using CLVP scoring.

**Impact**:
- **Speed**: Linear increase in generation time (more samples = more forward passes)
- **Quality**: Diminishing returns after ~256 samples
- **Memory**: Each sample requires VRAM

**Typical Values**:
- `1-16`: Ultra-fast, lower quality
- `32-96`: Fast, decent quality
- `128-256`: Standard, very good quality
- `256-512`: High quality, minimal gains above 256

**Recommendation**: Use 96-256 for most use cases. Values above 256 rarely improve quality significantly.

---

#### `diffusion_iterations` (10-1000)
**What it does**: Number of diffusion steps used to convert acoustic tokens into mel-spectrograms. More iterations allow the diffusion model more refinement steps.

**Impact**:
- **Speed**: Linear increase (each iteration is a forward pass)
- **Quality**: Significant improvement up to ~200 iterations, diminishing returns after ~400
- **Quality**: Below 50 iterations can sound muffled/bland

**Typical Values**:
- `10-30`: Ultra-fast, noticeable quality loss
- `50-80`: Fast, acceptable quality
- `100-200`: Standard, excellent quality
- `200-400`: High quality, best results
- `400+`: Diminishing returns, very slow

**Recommendation**: Use 80-200 for best speed/quality balance. Values above 400 are rarely worth the compute time.

---

#### `cond_free` (Boolean)
**What it does**: Enables classifier-free guidance during diffusion. When `True`, the model performs two forward passes per iteration: one with conditioning (voice/text) and one without, then blends them.

**Impact**:
- **Speed**: ~2x slower (double forward passes)
- **Quality**: Dramatically improves realism and voice consistency
- **Quality**: Reduces artifacts and improves naturalness

**Recommendation**: Always use `True` except for ultra_fast. The quality improvement is significant.

---

### Shared Parameters (Defaults Applied to All Presets)

#### `temperature` (0.0-2.0, default: 0.8)
**What it does**: Controls randomness in the autoregressive model's token sampling. Higher values = more diverse/creative outputs, lower = more deterministic/consistent.

**Effects**:
- **Low (0.5-0.7)**: More consistent, sometimes monotone, fewer variations
- **Medium (0.8-1.0)**: Balanced, natural variation (recommended)
- **High (1.2-2.0)**: More creative, can be less coherent, more varied intonation

**Use Cases**:
- Lower for consistent narration
- Higher for expressive/dramatic speech
- **Recommendation**: Keep at 0.8 unless you need more/less variation

---

#### `length_penalty` (0.0-5.0, default: 1.0)
**What it does**: Exponential penalty applied to sequence length during autoregressive generation. Higher values encourage shorter outputs.

**Effects**:
- **< 1.0**: Encourages longer sequences (can be verbose)
- **1.0**: No penalty (default, neutral)
- **> 1.0**: Encourages shorter sequences (can truncate)

**Use Cases**:
- Reduce if output is being cut short
- Increase if output is too verbose
- **Recommendation**: Keep at 1.0 unless you have length issues

---

#### `repetition_penalty` (1.0-5.0, default: 2.0)
**What it does**: Penalizes repeated tokens/phrases. Higher values strongly discourage repetition.

**Effects**:
- **Low (1.0-1.5)**: More repetition allowed (can cause stuttering)
- **Medium (2.0-2.5)**: Good balance (recommended)
- **High (3.0-5.0)**: Very strict, can affect natural flow

**Use Cases**:
- Increase if you hear repeated words/phrases
- Decrease if output sounds unnatural/stilted
- **Recommendation**: Use 2.0-2.5 for most cases

---

#### `top_p` (0.0-1.0, default: 0.8)
**What it does**: Nucleus sampling threshold. Samples from the smallest set of tokens whose cumulative probability exceeds `top_p`. Lower = more focused/conservative, higher = more diverse.

**Effects**:
- **Low (0.5-0.7)**: More focused, conservative word choices
- **Medium (0.8-0.9)**: Balanced diversity (recommended)
- **High (0.95-1.0)**: More diverse, can be less coherent

**Use Cases**:
- Lower for consistent, predictable output
- Higher for more natural variation
- **Recommendation**: Keep at 0.8 unless you need more/less diversity

---

#### `cond_free_k` (0.0-5.0, default: 2.0)
**What it does**: Strength of classifier-free guidance blending. Controls how much the unconditioned (no voice) output influences the final result. Formula: `output = cond_present * (k+1) - cond_absent * k`

**Effects**:
- **Low (0.5-1.0)**: Less guidance, more voice-specific but potentially less natural
- **Medium (2.0-2.5)**: Good balance (recommended)
- **High (3.0-5.0)**: Strong guidance, more natural but can reduce voice distinctiveness

**Use Cases**:
- Increase if voice sounds unnatural/artificial
- Decrease if voice isn't distinct enough
- **Recommendation**: Use 2.0-2.5 for most cases

---

#### `diffusion_temperature` (0.0-2.0, default: 1.0)
**What it does**: Controls variance of noise fed into the diffusion model. Higher = more variation in the generated mel-spectrogram.

**Effects**:
- **Low (0.5-0.8)**: More "mean" prediction, can sound bland/smeared
- **Medium (1.0-1.2)**: Good balance (recommended)
- **High (1.5-2.0)**: More variation, can introduce artifacts

**Use Cases**:
- Increase slightly (1.1-1.2) if output sounds too uniform
- Decrease if output has artifacts
- **Recommendation**: Keep at 1.0 unless you have specific issues

---

## üìà Complete Parameter Tables

### All Parameters by Preset (With Defaults)

| Parameter | ultra_fast | fast | standard | high_quality |
|-----------|:----------:|:---:|:--------:|:------------:|
| `num_autoregressive_samples` | 16 | 96 | 256 | 256 |
| `diffusion_iterations` | 30 | 80 | 200 | 400 |
| `cond_free` | `False` | `True` | `True` | `True` |
| `temperature` | 0.8 | 0.8 | 0.8 | 0.8 |
| `length_penalty` | 1.0 | 1.0 | 1.0 | 1.0 |
| `repetition_penalty` | 2.0 | 2.0 | 2.0 | 2.0 |
| `top_p` | 0.8 | 0.8 | 0.8 | 0.8 |
| `cond_free_k` | 2.0 | 2.0 | 2.0 | 2.0 |
| `diffusion_temperature` | 1.0 | 1.0 | 1.0 | 1.0 |

### Speed vs Quality Trade-offs

| Preset | Est. Time* | Quality | Use Case |
|--------|:---------:|:-------:|----------|
| `ultra_fast` | 0.5-1s | 6/10 | Quick previews, testing |
| `fast` | 2-5s | 8/10 | General use, batch processing |
| `standard` | 10-20s | 9/10 | Production, high-quality output |
| `high_quality` | 30-60s | 9.5/10 | Final output, premium quality |

*Per sentence, GPU-accelerated

---

## üéõÔ∏è Tuning Examples

### Example 1: Optimized Fast Preset
```python
wav = tts.tts_with_preset(
    text,
    preset="fast",
    repetition_penalty=2.5,  # Reduce repetition
    top_p=0.75,               # More focused
    diffusion_temperature=0.9  # Slightly less variation
)
```

### Example 2: High-Quality Standard Preset
```python
wav = tts.tts_with_preset(
    text,
    preset="standard",
    temperature=0.7,           # More consistent
    repetition_penalty=2.5,   # Less repetition
    cond_free_k=2.5,          # Stronger guidance
    diffusion_temperature=1.1  # Slightly more variation
)
```

### Example 3: Custom Ultra-Fast
```python
wav = tts.tts_with_preset(
    text,
    preset="ultra_fast",
    num_autoregressive_samples=8,   # Even faster
    diffusion_iterations=20,         # Fewer iterations
    temperature=0.6,                 # More deterministic
    repetition_penalty=2.5          # Reduce artifacts
)
```

### Example 4: Maximum Quality High-Quality Preset
```python
wav = tts.tts_with_preset(
    text,
    preset="high_quality",
    num_autoregressive_samples=512,  # Maximum samples for best selection
    diffusion_iterations=400,        # Maximum iterations (preset default)
    temperature=0.75,                # Balanced consistency
    repetition_penalty=2.5,          # Strong anti-repetition
    top_p=0.85,                      # Slightly more diversity
    cond_free_k=2.5,                 # Strong classifier-free guidance
    diffusion_temperature=1.1        # Enhanced variation
)
```

---

## üöÄ CLI Usage

```bash
python src/tutortoietts/cli/generate.py "Hello world" --preset fast --output hello.wav
```

**Available Presets**: `ultra_fast`, `fast`, `standard`, `high_quality`

---

## üìö Additional Resources

- See [docs/USAGE_GUIDE.md](docs/USAGE_GUIDE.md) for detailed usage examples
- See [MODEL.md](MODEL.md) for architecture details
- See [PERFORMANCE.md](PERFORMANCE.md) for performance tuning guides


